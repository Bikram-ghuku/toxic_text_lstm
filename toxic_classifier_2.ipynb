{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd1e719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:42:48.221894Z",
     "iopub.status.busy": "2025-06-24T19:42:48.220985Z",
     "iopub.status.idle": "2025-06-24T19:42:51.988134Z",
     "shell.execute_reply": "2025-06-24T19:42:51.987137Z"
    },
    "papermill": {
     "duration": 3.773918,
     "end_time": "2025-06-24T19:42:51.989659",
     "exception": false,
     "start_time": "2025-06-24T19:42:48.215741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/toxic-comment/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620153df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:42:51.998379Z",
     "iopub.status.busy": "2025-06-24T19:42:51.998119Z",
     "iopub.status.idle": "2025-06-24T19:42:53.907639Z",
     "shell.execute_reply": "2025-06-24T19:42:53.906883Z"
    },
    "papermill": {
     "duration": 1.91554,
     "end_time": "2025-06-24T19:42:53.909289",
     "exception": false,
     "start_time": "2025-06-24T19:42:51.993749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03437cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:42:53.918982Z",
     "iopub.status.busy": "2025-06-24T19:42:53.918565Z",
     "iopub.status.idle": "2025-06-24T19:43:11.104236Z",
     "shell.execute_reply": "2025-06-24T19:43:11.103345Z"
    },
    "papermill": {
     "duration": 17.191746,
     "end_time": "2025-06-24T19:43:11.105829",
     "exception": false,
     "start_time": "2025-06-24T19:42:53.914083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>cant make real suggestions improvement wondere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>second time asking view completely contradicts...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>spitzer umm theres actual article prostitution...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>looks like actually put speedy first version d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>really dont think understand came idea bad rig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  explanation edits made username hardcore metal...   \n",
       "1       000103f0d9cfb60f  daww matches background colour im seemingly st...   \n",
       "2       000113f07ec002fd  hey man im really trying edit war guy constant...   \n",
       "3       0001b41b1c6bb37e  cant make real suggestions improvement wondere...   \n",
       "4       0001d958c54c6e35                sir hero chance remember page thats   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  second time asking view completely contradicts...   \n",
       "159567  ffea4adeee384e90               ashamed horrible thing put talk page   \n",
       "159568  ffee36eab5c267c9  spitzer umm theres actual article prostitution...   \n",
       "159569  fff125370e4aaaf3  looks like actually put speedy first version d...   \n",
       "159570  fff46fc426af1f9a  really dont think understand came idea bad rig...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = str(text)    \n",
    "    text = re.sub(r'[\\n\\r\\t\\f\\v]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word and word not in stop_words and len(word) > 1]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "df['comment_text'] = df['comment_text'].apply(clean_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b449ac5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:43:11.116013Z",
     "iopub.status.busy": "2025-06-24T19:43:11.115287Z",
     "iopub.status.idle": "2025-06-24T19:43:11.195704Z",
     "shell.execute_reply": "2025-06-24T19:43:11.194852Z"
    },
    "papermill": {
     "duration": 0.086983,
     "end_time": "2025-06-24T19:43:11.197212",
     "exception": false,
     "start_time": "2025-06-24T19:43:11.110229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant make real suggestions improvement wondere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>second time asking view completely contradicts...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>spitzer umm theres actual article prostitution...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>looks like actually put speedy first version d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>really dont think understand came idea bad rig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic  \\\n",
       "0       explanation edits made username hardcore metal...      0   \n",
       "1       daww matches background colour im seemingly st...      0   \n",
       "2       hey man im really trying edit war guy constant...      0   \n",
       "3       cant make real suggestions improvement wondere...      0   \n",
       "4                     sir hero chance remember page thats      0   \n",
       "...                                                   ...    ...   \n",
       "159566  second time asking view completely contradicts...      0   \n",
       "159567               ashamed horrible thing put talk page      0   \n",
       "159568  spitzer umm theres actual article prostitution...      0   \n",
       "159569  looks like actually put speedy first version d...      0   \n",
       "159570  really dont think understand came idea bad rig...      0   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0                  0        0       0       0              0  \n",
       "1                  0        0       0       0              0  \n",
       "2                  0        0       0       0              0  \n",
       "3                  0        0       0       0              0  \n",
       "4                  0        0       0       0              0  \n",
       "...              ...      ...     ...     ...            ...  \n",
       "159566             0        0       0       0              0  \n",
       "159567             0        0       0       0              0  \n",
       "159568             0        0       0       0              0  \n",
       "159569             0        0       0       0              0  \n",
       "159570             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().drop(['id'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f902af9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:43:11.206179Z",
     "iopub.status.busy": "2025-06-24T19:43:11.205860Z",
     "iopub.status.idle": "2025-06-24T19:43:12.691992Z",
     "shell.execute_reply": "2025-06-24T19:43:12.691107Z"
    },
    "papermill": {
     "duration": 1.492313,
     "end_time": "2025-06-24T19:43:12.693534",
     "exception": false,
     "start_time": "2025-06-24T19:43:11.201221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(texts, max_vocab=50000):\n",
    "    counter = Counter()\n",
    "    for line in texts:\n",
    "        counter.update(line.split())\n",
    "    most_common = counter.most_common(max_vocab - 2)\n",
    "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "    vocab.update({word: i+2 for i, (word, _) in enumerate(most_common)})\n",
    "    return vocab\n",
    "\n",
    "def encode(text, vocab):\n",
    "    return [vocab.get(w, vocab[\"<UNK>\"]) for w in text.split()]\n",
    "\n",
    "vocab = build_vocab(df['comment_text'].tolist(), max_vocab=216477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c82a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:43:12.703121Z",
     "iopub.status.busy": "2025-06-24T19:43:12.702540Z",
     "iopub.status.idle": "2025-06-24T19:43:12.791377Z",
     "shell.execute_reply": "2025-06-24T19:43:12.790688Z"
    },
    "papermill": {
     "duration": 0.094949,
     "end_time": "2025-06-24T19:43:12.792796",
     "exception": false,
     "start_time": "2025-06-24T19:43:12.697847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.drop(['comment_text'], axis = 1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['comment_text'], y, test_size=0.2, random_state=42, stratify=y[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bc8841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:43:12.801916Z",
     "iopub.status.busy": "2025-06-24T19:43:12.801354Z",
     "iopub.status.idle": "2025-06-24T19:43:17.340203Z",
     "shell.execute_reply": "2025-06-24T19:43:17.339197Z"
    },
    "papermill": {
     "duration": 4.544933,
     "end_time": "2025-06-24T19:43:17.341754",
     "exception": false,
     "start_time": "2025-06-24T19:43:12.796821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f537b7b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:43:17.350744Z",
     "iopub.status.busy": "2025-06-24T19:43:17.350316Z",
     "iopub.status.idle": "2025-06-24T19:43:17.895343Z",
     "shell.execute_reply": "2025-06-24T19:43:17.894574Z"
    },
    "papermill": {
     "duration": 0.550753,
     "end_time": "2025-06-24T19:43:17.896659",
     "exception": false,
     "start_time": "2025-06-24T19:43:17.345906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  9.4337,  98.4206,  17.9429, 334.0551,  19.3048, 113.3871],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.tensor(y_train)\n",
    "pos_counts = y_train.sum(dim=0).float()\n",
    "neg_counts = len(y_train) - pos_counts\n",
    "pos_weights = neg_counts / pos_counts\n",
    "pos_weights = pos_weights.to(device) \n",
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491ac678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:43:17.905940Z",
     "iopub.status.busy": "2025-06-24T19:43:17.905632Z",
     "iopub.status.idle": "2025-06-24T19:43:28.100193Z",
     "shell.execute_reply": "2025-06-24T19:43:28.099094Z"
    },
    "papermill": {
     "duration": 10.201414,
     "end_time": "2025-06-24T19:43:28.102287",
     "exception": false,
     "start_time": "2025-06-24T19:43:17.900873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0rc1\r\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\r\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0rc1)\r\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2025.4.26)\r\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.3.1)\r\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\r\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\r\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\r\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\r\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\r\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\r\n",
      "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\r\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\r\n",
      "Building wheels for collected packages: googletrans\r\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=6e410d52ad2ffc2918a915e57c6721e50e71de796678ba77920dce9f13ec56e5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\r\n",
      "Successfully built googletrans\r\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\r\n",
      "  Attempting uninstall: hyperframe\r\n",
      "    Found existing installation: hyperframe 6.1.0\r\n",
      "    Uninstalling hyperframe-6.1.0:\r\n",
      "      Successfully uninstalled hyperframe-6.1.0\r\n",
      "  Attempting uninstall: hpack\r\n",
      "    Found existing installation: hpack 4.1.0\r\n",
      "    Uninstalling hpack-4.1.0:\r\n",
      "      Successfully uninstalled hpack-4.1.0\r\n",
      "  Attempting uninstall: h11\r\n",
      "    Found existing installation: h11 0.14.0\r\n",
      "    Uninstalling h11-0.14.0:\r\n",
      "      Successfully uninstalled h11-0.14.0\r\n",
      "  Attempting uninstall: chardet\r\n",
      "    Found existing installation: chardet 5.2.0\r\n",
      "    Uninstalling chardet-5.2.0:\r\n",
      "      Successfully uninstalled chardet-5.2.0\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.10\r\n",
      "    Uninstalling idna-3.10:\r\n",
      "      Successfully uninstalled idna-3.10\r\n",
      "  Attempting uninstall: h2\r\n",
      "    Found existing installation: h2 4.2.0\r\n",
      "    Uninstalling h2-4.2.0:\r\n",
      "      Successfully uninstalled h2-4.2.0\r\n",
      "  Attempting uninstall: httpcore\r\n",
      "    Found existing installation: httpcore 1.0.7\r\n",
      "    Uninstalling httpcore-1.0.7:\r\n",
      "      Successfully uninstalled httpcore-1.0.7\r\n",
      "  Attempting uninstall: httpx\r\n",
      "    Found existing installation: httpx 0.28.1\r\n",
      "    Uninstalling httpx-0.28.1:\r\n",
      "      Successfully uninstalled httpx-0.28.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "openai 1.70.0 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "langsmith 0.3.23 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\r\n",
      "google-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-genai 1.9.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.13.3 which is incompatible.\r\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0rc1 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef6c25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:43:28.116499Z",
     "iopub.status.busy": "2025-06-24T19:43:28.116225Z",
     "iopub.status.idle": "2025-06-24T19:57:55.403679Z",
     "shell.execute_reply": "2025-06-24T19:57:55.402769Z"
    },
    "papermill": {
     "duration": 867.296281,
     "end_time": "2025-06-24T19:57:55.405384",
     "exception": false,
     "start_time": "2025-06-24T19:43:28.109103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column 3: 100%|██████████| 762/762 [14:26<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "import random, time, torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "translator = Translator()\n",
    "langs = ['es', 'fr', 'de']\n",
    "\n",
    "for i in range(y_train.shape[1]):\n",
    "    if pos_weights[i] < 200: continue\n",
    "    pos = torch.where(y_train[:, i] == 1)[0]\n",
    "    needed = (y_train[:, i] == 0).sum() - len(pos)\n",
    "    if needed <= 0: continue\n",
    "    \n",
    "    new_texts, new_labels = [], []\n",
    "    for _ in tqdm(range(min(needed, 2 * len(pos))), desc=f'Column {i}'):\n",
    "        idx = random.choice(pos.tolist())\n",
    "        try:\n",
    "            t1 = translator.translate(X_train[idx], dest=random.choice(langs))\n",
    "            time.sleep(0.1)\n",
    "            t2 = translator.translate(t1.text, dest='en')\n",
    "            new_texts.append(t2.text)\n",
    "        except: new_texts.append(X_train.iloc[idx])\n",
    "        new_labels.append(y_train[idx])\n",
    "    \n",
    "    X_train = X_train.tolist() + new_texts\n",
    "    y_train = torch.cat([y_train, torch.stack(new_labels)])\n",
    "\n",
    "s = torch.randperm(len(X_train))\n",
    "X_train, y_train = [X_train[i] for i in s], y_train[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e355447d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:57:55.475402Z",
     "iopub.status.busy": "2025-06-24T19:57:55.474587Z",
     "iopub.status.idle": "2025-06-24T19:57:55.493712Z",
     "shell.execute_reply": "2025-06-24T19:57:55.492825Z"
    },
    "papermill": {
     "duration": 0.053919,
     "end_time": "2025-06-24T19:57:55.495294",
     "exception": false,
     "start_time": "2025-06-24T19:57:55.441375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/354795991.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  8.9203,  87.2598,  16.8012, 111.3517,  17.9771, 100.1165])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.tensor(y_train)\n",
    "pos_counts = y_train.sum(dim=0).float()\n",
    "neg_counts = len(y_train) - pos_counts\n",
    "neg_counts / pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf1f57e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:57:55.564624Z",
     "iopub.status.busy": "2025-06-24T19:57:55.564325Z",
     "iopub.status.idle": "2025-06-24T19:57:57.472611Z",
     "shell.execute_reply": "2025-06-24T19:57:57.471762Z"
    },
    "papermill": {
     "duration": 1.944825,
     "end_time": "2025-06-24T19:57:57.474264",
     "exception": false,
     "start_time": "2025-06-24T19:57:55.529439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_encode = [encode(sent, vocab) for sent in X_train]\n",
    "X_test_encode = [encode(sent, vocab) for sent in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91153471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:57:57.539294Z",
     "iopub.status.busy": "2025-06-24T19:57:57.538652Z",
     "iopub.status.idle": "2025-06-24T19:57:57.546815Z",
     "shell.execute_reply": "2025-06-24T19:57:57.546008Z"
    },
    "papermill": {
     "duration": 0.042285,
     "end_time": "2025-06-24T19:57:57.548062",
     "exception": false,
     "start_time": "2025-06-24T19:57:57.505777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/878285299.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.texts[idx], dtype=torch.long), self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    lengths = [len(x) for x in texts]\n",
    "    padded = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    return padded, torch.stack(labels)\n",
    "\n",
    "train_ds = ToxicDataset(X_train_encode, y_train)\n",
    "val_ds = ToxicDataset(X_test_encode, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29279c2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:57:57.616294Z",
     "iopub.status.busy": "2025-06-24T19:57:57.615977Z",
     "iopub.status.idle": "2025-06-24T19:57:57.622697Z",
     "shell.execute_reply": "2025-06-24T19:57:57.621841Z"
    },
    "papermill": {
     "duration": 0.041116,
     "end_time": "2025-06-24T19:57:57.624151",
     "exception": false,
     "start_time": "2025-06-24T19:57:57.583035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleBiLSTMToxicClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=64, dropout=0.3):\n",
    "        super(SimpleBiLSTMToxicClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, \n",
    "                           bidirectional=True, dropout=dropout)\n",
    "        \n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(embedded)\n",
    "        \n",
    "        hidden = torch.cat((h_n[-2], h_n[-1]), dim=1) \n",
    "        \n",
    "        output = self.dropout(hidden)\n",
    "        logits = self.fc(output)\n",
    "        \n",
    "        return torch.sigmoid(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ed961a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:57:57.694128Z",
     "iopub.status.busy": "2025-06-24T19:57:57.693427Z",
     "iopub.status.idle": "2025-06-24T19:57:57.701985Z",
     "shell.execute_reply": "2025-06-24T19:57:57.700959Z"
    },
    "papermill": {
     "duration": 0.044694,
     "end_time": "2025-06-24T19:57:57.703354",
     "exception": false,
     "start_time": "2025-06-24T19:57:57.658660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3491468082.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train)\n"
     ]
    }
   ],
   "source": [
    "y_train = torch.tensor(y_train)\n",
    "pos_counts = y_train.sum(dim=0).float()\n",
    "neg_counts = len(y_train) - pos_counts\n",
    "pos_weights = neg_counts / pos_counts\n",
    "pos_weights = pos_weights.to(device) \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd427e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:57:57.776333Z",
     "iopub.status.busy": "2025-06-24T19:57:57.775517Z",
     "iopub.status.idle": "2025-06-24T19:57:57.781778Z",
     "shell.execute_reply": "2025-06-24T19:57:57.781066Z"
    },
    "papermill": {
     "duration": 0.043593,
     "end_time": "2025-06-24T19:57:57.783027",
     "exception": false,
     "start_time": "2025-06-24T19:57:57.739434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8.9203,  87.2598,  16.8012, 111.3517,  17.9771, 100.1165],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4392113d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:57:57.851088Z",
     "iopub.status.busy": "2025-06-24T19:57:57.850383Z",
     "iopub.status.idle": "2025-06-24T20:07:01.876913Z",
     "shell.execute_reply": "2025-06-24T20:07:01.876029Z"
    },
    "papermill": {
     "duration": 544.061823,
     "end_time": "2025-06-24T20:07:01.878447",
     "exception": false,
     "start_time": "2025-06-24T19:57:57.816624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 1.1645 | Val Loss: 1.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Train Loss: 1.0919 | Val Loss: 1.0232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Train Loss: 1.0621 | Val Loss: 1.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Train Loss: 1.0470 | Val Loss: 0.9942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Train Loss: 1.0500 | Val Loss: 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Train Loss: 1.0382 | Val Loss: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Train Loss: 1.1628 | Val Loss: 0.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Train Loss: 1.0368 | Val Loss: 0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Train Loss: 1.3633 | Val Loss: 1.4177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | Train Loss: 1.0686 | Val Loss: 0.9936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | Train Loss: 1.0722 | Val Loss: 0.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | Train Loss: 1.0332 | Val Loss: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | Train Loss: 1.0298 | Val Loss: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | Train Loss: 1.0294 | Val Loss: 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | Train Loss: 1.0272 | Val Loss: 0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | Train Loss: 1.0270 | Val Loss: 0.9843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | Train Loss: 1.1055 | Val Loss: 1.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | Train Loss: 1.2273 | Val Loss: 1.5115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | Train Loss: 1.3828 | Val Loss: 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | Train Loss: 1.0874 | Val Loss: 0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "model = SimpleBiLSTMToxicClassifier(vocab_size=len(vocab)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
    "\n",
    "    for batch_x, batch_y in train_loop:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "        for batch_x, batch_y in val_loop:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_val_loss += loss.item()\n",
    "            val_loop.set_postfix(val_loss=loss.item())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    # Epoch summary\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8165f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:07:04.716515Z",
     "iopub.status.busy": "2025-06-24T20:07:04.715268Z",
     "iopub.status.idle": "2025-06-24T20:07:06.863021Z",
     "shell.execute_reply": "2025-06-24T20:07:06.862189Z"
    },
    "papermill": {
     "duration": 3.498171,
     "end_time": "2025-06-24T20:07:06.864421",
     "exception": false,
     "start_time": "2025-06-24T20:07:03.366250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (micro): 0.5086316863678884\n",
      "Accuracy Score:  0.8721290929030237\n",
      "AUR ROC:  0.8999309169256281\n",
      "Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.69      0.79      0.74      3059\n",
      " severe_toxic       0.13      0.96      0.24       311\n",
      "      obscene       0.54      0.90      0.67      1710\n",
      "       threat       0.03      0.72      0.07        97\n",
      "       insult       0.47      0.87      0.61      1590\n",
      "identity_hate       0.09      0.89      0.16       289\n",
      "\n",
      "    micro avg       0.36      0.85      0.51      7056\n",
      "    macro avg       0.33      0.86      0.41      7056\n",
      " weighted avg       0.55      0.85      0.64      7056\n",
      "  samples avg       0.04      0.08      0.05      7056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in val_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        outputs = model(batch_x).cpu()\n",
    "        preds = (outputs > 0.5).float()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(batch_y)\n",
    "\n",
    "y_pred = torch.cat(all_preds).numpy()\n",
    "y_true = torch.cat(all_labels).numpy()\n",
    "\n",
    "print(\"F1 Score (micro):\", f1_score(y_true, y_pred, average='micro'))\n",
    "print(\"Accuracy Score: \", accuracy_score(y_true, y_pred))\n",
    "print(\"AUR ROC: \", roc_auc_score(y_true, y_pred))\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "print(\"Classification Report: \\n\",classification_report(y_true, y_pred, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7582791,
     "sourceId": 12049035,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1467.520488,
   "end_time": "2025-06-24T20:07:11.160237",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-24T19:42:43.639749",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
